---
title: "Benchmarking of Duo-Labs Codebase vs. Botometer"
author: "Mihai Avram"
date: "9/24/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(car)
library(mlr)
library(ada)
library(kknn)
library(randomForest)
library(e1071)
library(sparklyr)
set.seed(26)
```

```{r}
spark_install(version = "2.1.0")
sc <- sparklyr::spark_connect(master = "local")
```

```{r}
onur_2017_data_human <- collect(spark_read_parquet(sc, 
                                           "onur_2017_data_human",
                                           "/home/mavram/Projects/OpenKasm/TwitterReposAnalysis/output-analysis/onur-2017/humans/"))
onur_2017_data_bot <- collect(spark_read_parquet(sc, 
                                           "onur_2017_data_bot",
                                           "/home/mavram/Projects/OpenKasm/TwitterReposAnalysis/output-analysis/onur-2017/bots/"))
onur_2017_data_human <- as.data.frame(onur_2017_data_human)
onur_2017_data_bot <- as.data.frame(onur_2017_data_bot)
```

```{r}
# setting target column
onur_2017_data_human$is_bot <- 0
onur_2017_data_bot$is_bot <- 1
```

```{r}
factor_columns <- c("is_default_profile", "is_protected", "is_geo_enabled", "is_verified", "is_bot")
add_factors <- function(account_df, columns) {
  for (c in columns) {
    account_df[, c] <- as.factor(account_df[, c])
  }
  return(account_df)
}

onur_2017_data_human <- add_factors(onur_2017_data_human, factor_columns)
onur_2017_data_bot <- add_factors(onur_2017_data_bot, factor_columns)
```

```{r}
feature_columns <- c("is_verified", "is_default_profile", "is_geo_enabled",
                                 "ratio_followers_friends", "screen_name_entropy",
                                 "numbers_at_beginning_of_screen_name", "numbers_at_end_of_screen_name",
                                 "favorite_rate", "is_protected",  "tweet_rate", "is_bot")

get_feature_data <- function(account_data, training=T, scale=T){
  feature_columns <- c("is_verified", "is_default_profile", "is_geo_enabled",
                                 "ratio_followers_friends", "screen_name_entropy",
                                 "numbers_at_beginning_of_screen_name", "numbers_at_end_of_screen_name",
                                 "favorite_rate", "is_protected",  "tweet_rate")
  if(training){
    feature_columns <- c(feature_columns, "is_bot")
  }
  
  feature_data <- account_data[, feature_columns]

  if(scale){
    scaled_feature_data <- feature_data

    scaled_feature_data[, -c(1, 2, 3, 9, 11)] <- scale(feature_data[, -c(1, 2, 3, 9, 11)]) 
    
    feature_data <- scaled_feature_data
  }
  
  return(feature_data)
}

feature_onur_2017_data_human <- get_feature_data(onur_2017_data_human, T, F)
feature_onur_2017_data_bot <- get_feature_data(onur_2017_data_bot, T, F)
```

```{r}
onur_2017_data <- rbind(feature_onur_2017_data_human, feature_onur_2017_data_bot)
print('DATA:')
print(onur_2017_data)
```

```{r}
# cl <- makePSOCKcluster(5)
# registerDoParallel(cl)
tasks <- list( 
  makeClassifTask(id="OnurData", data=onur_2017_data, target="is_bot", positive="1"),
  smote(makeClassifTask(id="OnurDataSmote", data=onur_2017_data, target="is_bot", positive="1"), rate=1.33)
)

lrns <- list(
  makeLearner("classif.ada", id = "ada", predict.type="prob"), 
  makeLearner("classif.logreg", id ="logisticRegression", predict.type="prob"), 
  makeLearner("classif.rpart", id = "rpart", predict.type="prob"),
  makeLearner("classif.randomForest", id = "randomForest", predict.type="prob"),
  makeLearner("classif.naiveBayes", id = "naiveBayes", predict.type="prob")
)
rdesc <- makeResampleDesc("CV", iters = 10)
meas <- list(acc, auc, ppv, f1, kappa, tpr, brier, timetrain)
bmr <- benchmark(lrns, tasks, rdesc, meas)
models <- getBMRModels(bmr)
# stopCluster(cl)
```